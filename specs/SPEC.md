# Tech Digest - Product Specification

## Overview

Tech Digest is a daily tech news aggregator that scrapes popular developer communities, uses Claude to intelligently process and categorize content, and presents a curated, searchable digest via a static site hosted on GitHub Pages.

---

## Content Strategy

### Data Sources

| Source | Content Type | Selection Criteria |
|--------|--------------|-------------------|
| Hacker News | Top stories only (no Show/Ask/Jobs) | Top 25 by points |
| Reddit | r/programming, r/webdev, r/machinelearning, r/netsec, r/devops, r/singularity, r/coding, r/artificial, r/startups, r/cscareerquestions, r/experienceddevs | 100+ upvotes, top 25 per subreddit |
| Lobste.rs | All tech content | Top 25 by score |
| dev.to | All tech content | Top 25 by reactions |

**Total items before processing**: ~100-125 items per day

### Content Processing

1. **Scraping**: Pull top 25 items from each source
2. **Deduplication**: Claude identifies stories appearing across multiple sources, merges them with attribution ("Seen on HN, Reddit")
3. **Categorization**: Claude semantically classifies each item into categories (not source-driven)
4. **Analysis**: For each item, Claude generates:
   - Brief summary (2-3 sentences)
   - Extended analysis with community sentiment
   - Analysis based on top 10-20 comments by score
5. **Ranking**: Items sorted by hotness score

**Final output**: 30-50 items per daily digest

### Hotness Algorithm

```
hotness = (upvotes * 0.5) + (comments * 0.5)
```

- Pure engagement-based (no recency factor within daily window)
- Balanced 50/50 weighting between upvotes and comments
- Normalized across sources before combining

### Link Handling

- Primary link: Original article URL
- Secondary link: Discussion page (HN comments, Reddit thread)
- Links used as-is (no tracing to original sources)

---

## Categories

### Fixed Categories

| Category | Description |
|----------|-------------|
| AI/ML | Artificial intelligence, machine learning, LLMs, computer vision |
| Development | Programming languages, frameworks, tools, best practices, frontend/backend |
| Infrastructure | DevOps, cloud, databases, security, networking, systems |
| Career | Industry news, job market, layoffs, company culture, career advice |
| Other | Trending topics that don't fit above, emerging categories |

Claude assigns items to categories semantically based on content analysis. Items can only belong to one category.

---

## User Interface

### Design Principles

- **Mobile-first**: Design for mobile, scale up to desktop
- **Minimal/utilitarian**: No logo, text-based header, focus on content
- **Headline dominant**: Large titles, summaries secondary
- **System theme**: Auto-detect OS dark/light preference

### Navigation

- **Filter chips**: Mixed feed by default with category filter chips
- **No keyboard shortcuts**: Standard browser behavior only
- **Day navigation**: Today, Yesterday, 2 days ago... up to 7 days

### Card Design

#### Collapsed State (Default)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Category chip]                    [Source(s)] â”‚
â”‚                                                â”‚
â”‚ Headline Title Goes Here                       â”‚
â”‚                                                â”‚
â”‚ Brief 2-3 sentence summary generated by        â”‚
â”‚ Claude based on the article content...         â”‚
â”‚                                                â”‚
â”‚ â†‘ 234  ğŸ’¬ 89                        [Expand â–¼] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Expanded State
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ [Category chip]                    [Source(s)] â”‚
â”‚                                                â”‚
â”‚ Headline Title Goes Here                       â”‚
â”‚                                                â”‚
â”‚ Brief 2-3 sentence summary...                  â”‚
â”‚                                                â”‚
â”‚ â”€â”€ Claude's Analysis â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚                                                â”‚
â”‚ Extended summary with more context about the   â”‚
â”‚ article and its significance...                â”‚
â”‚                                                â”‚
â”‚ Community Sentiment:                           â”‚
â”‚ The discussion is largely positive, with       â”‚
â”‚ developers praising the approach but raising   â”‚
â”‚ concerns about...                              â”‚
â”‚                                                â”‚
â”‚ â†‘ 234  ğŸ’¬ 89                      [Collapse â–²] â”‚
â”‚                                                â”‚
â”‚ [Read Article â†’]  [View Discussion â†’]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Archive Navigation

- Rolling 7-day window
- Navigation: Today | Yesterday | 2 days ago | ... | 7 days ago
- Gaps allowed if cron misses a day (no backfill)
- Each day is a statically generated page

### Sharing

- Items have anchor links (`/2024-01-15#item-slug`)
- No dedicated per-item pages
- No SEO optimization (private tool)

---

## Technical Architecture

### Stack

- **Runtime**: Bun
- **Framework**: Next.js 14+ (App Router) with static export
- **Styling**: TailwindCSS + shadcn/ui
- **AI**: Claude Agent SDK (@anthropic-ai/agent-sdk)
- **Hosting**: GitHub Pages

### Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Local Machine  â”‚â”€â”€â”€â”€â–¶â”‚  GitHub Repo     â”‚â”€â”€â”€â”€â–¶â”‚  GitHub Pages   â”‚
â”‚  (Cron Job)     â”‚push â”‚  (data/*.json)   â”‚buildâ”‚  (Static Site)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â”‚                        â”‚
        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Scrape Sources â”‚     â”‚  GitHub Actions  â”‚
â”‚  + Claude API   â”‚     â”‚  (SSG Rebuild)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Cron Job (Local)

**Frequency**: Once daily

**Process**:
1. Scrape all sources (HN, Reddit, Lobste.rs, dev.to)
2. Send to Claude for processing:
   - Deduplicate across sources
   - Categorize semantically
   - Generate summaries and analysis
   - Calculate hotness scores
   - Selective web search for top stories needing context
3. Generate date-stamped JSON file (`data/2024-01-15.json`)
4. Push to GitHub repository
5. GitHub Actions triggered, rebuilds static site for last 7 days

**Failure handling**: Show stale data from last successful run

### JSON Schema

```json
{
  "date": "2024-01-15",
  "generated_at": "2024-01-15T08:00:00Z",
  "item_count": 42,
  "items": [
    {
      "id": "hn-38974123",
      "slug": "openai-announces-gpt5",
      "title": "OpenAI Announces GPT-5",
      "url": "https://openai.com/blog/gpt5",
      "category": "ai-ml",
      "sources": [
        {
          "name": "hackernews",
          "url": "https://news.ycombinator.com/item?id=38974123",
          "points": 892,
          "comments": 456
        },
        {
          "name": "reddit",
          "subreddit": "r/machinelearning",
          "url": "https://reddit.com/r/machinelearning/...",
          "upvotes": 2341,
          "comments": 189
        }
      ],
      "hotness_score": 1934,
      "summary": "OpenAI has announced GPT-5, their latest language model...",
      "analysis": {
        "extended_summary": "The announcement details significant improvements in...",
        "sentiment": "The community reaction is largely positive, with developers excited about..."
      }
    }
  ]
}
```

### File Naming

- Pattern: `data/YYYY-MM-DD.json`
- Example: `data/2024-01-15.json`

### GitHub Actions Workflow

Triggered on push to `data/` directory:
1. Checkout repository
2. Install dependencies
3. Build Next.js static export
4. Deploy to GitHub Pages

Only regenerates pages for dates with JSON files in last 7 days.

---

## Claude Integration

### API Configuration

- **Budget**: Unconstrained (use best model where it adds value)
- **Primary model**: Claude Opus for analysis quality
- **Web search**: Selective (only for top stories or when context is clearly missing)

### Processing Prompts

#### Deduplication & Categorization
```
Given these scraped items from multiple sources, identify duplicate
stories (same underlying news), merge them with source attribution,
and categorize each into exactly one of: AI/ML, Development,
Infrastructure, Career, Other.
```

#### Summary Generation
```
For each news item, generate:
1. A 2-3 sentence summary suitable for scanning
2. An extended analysis paragraph with deeper context
3. A community sentiment summary based on the top comments provided

Target audience: Tech professionals with deep technical knowledge.
Skip basic explanations. Be direct and information-dense.
```

### Web Search Usage

Claude uses web search tool selectively:
- Top 10 stories by hotness score
- Items where source content is thin/unclear
- Breaking news that may need additional context

---

## Pages & Routes

| Route | Description |
|-------|-------------|
| `/` | Today's digest (default) |
| `/YYYY-MM-DD` | Specific day's digest |

### URL Examples
- `/` - Today
- `/2024-01-15` - January 15, 2024
- `/2024-01-15#openai-announces-gpt5` - Deep link to specific item

---

## Constraints & Non-Goals

### Explicitly Out of Scope

- User accounts / authentication
- Personalization / saved preferences
- Comments / user-generated content
- Email newsletters
- Mobile app (PWA only if needed)
- Real-time updates (daily batch only)
- Analytics / tracking
- SEO optimization
- Keyboard shortcuts
- Backfilling missed days

### Performance Targets

- Initial page load: < 1s (static HTML)
- JSON file size: < 500KB per day
- Build time: < 2 minutes for 7-day rebuild

---

## Error Handling

| Scenario | Behavior |
|----------|----------|
| Cron fails to run | Gap in archive, show previous day |
| Claude API error | Use stale data, retry on next run |
| Source unavailable | Skip source, continue with others |
| Zero items for category | Show category with "No items today" |
| Sparse day (< 3 items in category) | Show anyway |

---

## Future Considerations

These are explicitly not in v1 but noted for potential future iterations:

- RSS feed generation
- Slack/Discord webhook integration
- Weekly summary rollups
- Trending topic detection over time
- Source credibility scoring

---

## Development Checklist

- [ ] Set up Next.js project with static export
- [ ] Implement scraping for all sources
- [ ] Build Claude processing pipeline
- [ ] Create JSON schema and generator
- [ ] Build UI components (cards, filters, navigation)
- [ ] Set up GitHub Actions workflow
- [ ] Configure GitHub Pages deployment
- [ ] Create local cron job script
- [ ] Test full pipeline end-to-end
- [ ] `bun run build` passes
- [ ] `bun run lint` passes
- [ ] `bun run typecheck` passes
